const OpenAI = require('openai');
const { SYSTEM_INSTRUCTIONS, getCachedResponse, getFallbackResponse } = require('./chatbot-instructions');

// Configuration OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

exports.handler = async (event, context) => {
  // Headers CORS
  const headers = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Content-Type',
    'Access-Control-Allow-Methods': 'POST, OPTIONS',
  };

  // Handle preflight requests
  if (event.httpMethod === 'OPTIONS') {
    return {
      statusCode: 200,
      headers,
      body: '',
    };
  }

  // Only allow POST requests
  if (event.httpMethod !== 'POST') {
    return {
      statusCode: 405,
      headers,
      body: JSON.stringify({ error: 'Method not allowed' }),
    };
  }

  try {
    const { message, conversationHistory = [] } = JSON.parse(event.body);

    if (!message || message.trim().length === 0) {
      return {
        statusCode: 400,
        headers,
        body: JSON.stringify({ error: 'Message is required' }),
      };
    }

    // V√©rifier d'abord le cache pour les questions fr√©quentes - TEST SIMPLE
    console.log('üîç MESSAGE RECU:', message);

    // Test direct pour les questions de prix
    const lowerMessage = message.toLowerCase();
    console.log('üìù Message en minuscules:', lowerMessage);

    if (lowerMessage.includes('prix') ||
        lowerMessage.includes('combien') ||
        lowerMessage.includes('co√ªt') ||
        lowerMessage.includes('cout') ||
        lowerMessage.includes('tarif') ||
        lowerMessage.includes('‚Ç¨') ||
        lowerMessage.includes('coute')) {

      console.log('‚úÖ DETECTED PRICE QUESTION - RETURNING CACHE');
      return {
        statusCode: 200,
        headers,
        body: JSON.stringify({
          response: "Le prix sp√©cial actuel est de 1 997‚Ç¨ pour la formation compl√®te SYST√àME VIRAL 100K‚Ñ¢ (au lieu de 3 997‚Ç¨). C'est un investissement qui peut transformer votre business ! üí∞",
          cached: true,
          usage: { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 }
        }),
      };
    }

    console.log('‚ùå Not a price question, continuing...');

    // Ancienne logique de cache si besoin
    const cachedResponse = getCachedResponse(message);
    if (cachedResponse) {
      return {
        statusCode: 200,
        headers,
        body: JSON.stringify({
          response: cachedResponse,
          cached: true,
          usage: { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 }
        }),
      };
    }

    // Utiliser le system prompt depuis le fichier d'instructions
    const systemPrompt = SYSTEM_INSTRUCTIONS.systemPrompt;

    // Pr√©parer les messages pour l'API
    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory.slice(-SYSTEM_INSTRUCTIONS.config.maxContextMessages), // Garder les derniers messages pour le contexte
      { role: 'user', content: message }
    ];

    // Appel √† l'API OpenAI avec configuration depuis le fichier d'instructions
    const completion = await openai.chat.completions.create({
      model: SYSTEM_INSTRUCTIONS.config.model,
      messages: messages,
      max_tokens: SYSTEM_INSTRUCTIONS.config.maxTokens,
      temperature: SYSTEM_INSTRUCTIONS.config.temperature,
      presence_penalty: 0.1,
      frequency_penalty: 0.1,
    });

    const response = completion.choices[0]?.message?.content;

    if (!response) {
      throw new Error('No response from OpenAI');
    }

    return {
      statusCode: 200,
      headers,
      body: JSON.stringify({
        response: response.trim(),
        usage: completion.usage,
      }),
    };

  } catch (error) {
    console.error('Chatbot error:', error);

    // Fallback response depuis le fichier d'instructions
    const fallbackResponse = getFallbackResponse();

    return {
      statusCode: 200,
      headers,
      body: JSON.stringify({
        response: fallbackResponse,
        error: true,
      }),
    };
  }
};
